[tool.poetry]
name = "llm-code-generation-eval"
version = "0.1.0"
description = "A project to run HumanEval dataset against different LLM models"
authors = ["Aneesh Chandran <aneeshcn01@gmail.com>"]
readme = "README.md"

[tool.poetry.dependencies]
python = "^3.9.0"
fire = "0.6.0"
multiprocess = "0.70.16"
tqdm = "4.66.4"
boto3 = "1.34.107"
datasets = "2.19.1"
urllib3= "1.26.7"
numpy = "1.26.4"

[build-system]
requires = ["poetry-core"]
build-backend = "poetry.core.masonry.api"
